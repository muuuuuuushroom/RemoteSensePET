{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1929353/2814093955.py:13: UserWarning: GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# torch.set_float32_matmul_precision('high')\n",
    "\n",
    "import warnings\n",
    "\n",
    "gpu_ok = False\n",
    "if torch.cuda.is_available():\n",
    "    device_cap = torch.cuda.get_device_capability()\n",
    "    if device_cap in ((7, 0), (8, 0), (9, 0)):\n",
    "        gpu_ok = True\n",
    "\n",
    "if not gpu_ok:\n",
    "    warnings.warn(\n",
    "        \"GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower \"\n",
    "        \"than expected.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the result of running `fn()` and the time it took for `fn()` to run,\n",
    "# in seconds. We use CUDA events and synchronization for the most accurate\n",
    "# measurements.\n",
    "def timed(fn):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    result = fn()\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    return result, start.elapsed_time(end) / 1000\n",
    "\n",
    "# Generates random input and targets data for the model, where `b` is\n",
    "# batch size.\n",
    "def generate_data(b):\n",
    "    return (\n",
    "        torch.randn(b, 3, 128, 128).to(torch.float32).cuda(),\n",
    "        torch.randint(1000, (b,)).cuda(),\n",
    "    )\n",
    "\n",
    "N_ITERS = 10\n",
    "\n",
    "from torchvision.models import densenet121\n",
    "def init_model():\n",
    "    return densenet121().to(torch.float32).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager: 2.996556884765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slcao/.conda/envs/dinov2/lib/python3.9/site-packages/torch/_inductor/compile_fx.py:90: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "[2024-07-12 16:39:07,853] torch._inductor.utils: [WARNING] skipping cudagraphs due to input mutation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile: 35.974046875\n"
     ]
    }
   ],
   "source": [
    "model = init_model()\n",
    "\n",
    "# Reset since we are using a different mode.\n",
    "import torch._dynamo\n",
    "torch._dynamo.reset()\n",
    "\n",
    "model_opt = torch.compile(model, mode=\"reduce-overhead\")\n",
    "\n",
    "inp = generate_data(16)[0]\n",
    "with torch.no_grad():\n",
    "    print(\"eager:\", timed(lambda: model(inp))[1])\n",
    "    print(\"compile:\", timed(lambda: model_opt(inp))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager eval time 0: 0.019986431121826173\n",
      "eager eval time 1: 0.01766307258605957\n",
      "eager eval time 2: 0.017738752365112305\n",
      "eager eval time 3: 0.01589964771270752\n",
      "eager eval time 4: 0.016094207763671875\n",
      "eager eval time 5: 0.015523615837097169\n",
      "eager eval time 6: 0.015485695838928223\n",
      "eager eval time 7: 0.01773353576660156\n",
      "eager eval time 8: 0.01754649543762207\n",
      "eager eval time 9: 0.017763328552246094\n",
      "~~~~~~~~~~\n",
      "compile eval time 0: 0.01704960060119629\n",
      "compile eval time 1: 0.017118207931518553\n",
      "compile eval time 2: 0.01782067108154297\n",
      "compile eval time 3: 0.01662156867980957\n",
      "compile eval time 4: 0.01719910430908203\n",
      "compile eval time 5: 0.017386335372924805\n",
      "compile eval time 6: 0.019425344467163087\n",
      "compile eval time 7: 0.01880166435241699\n",
      "compile eval time 8: 0.019574783325195313\n",
      "compile eval time 9: 0.016857088088989256\n",
      "~~~~~~~~~~\n",
      "(eval) eager median: 0.01760478401184082, compile median: 0.017292719841003418, speedup: 1.0180459854613184x\n",
      "~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "eager_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)[0]\n",
    "    with torch.no_grad():\n",
    "        _, eager_time = timed(lambda: model(inp))\n",
    "    eager_times.append(eager_time)\n",
    "    print(f\"eager eval time {i}: {eager_time}\")\n",
    "\n",
    "print(\"~\" * 10)\n",
    "\n",
    "compile_times = []\n",
    "for i in range(N_ITERS):\n",
    "    inp = generate_data(16)[0]\n",
    "    with torch.no_grad():\n",
    "        _, compile_time = timed(lambda: model_opt(inp))\n",
    "    compile_times.append(compile_time)\n",
    "    print(f\"compile eval time {i}: {compile_time}\")\n",
    "print(\"~\" * 10)\n",
    "\n",
    "import numpy as np\n",
    "eager_med = np.median(eager_times)\n",
    "compile_med = np.median(compile_times)\n",
    "speedup = eager_med / compile_med\n",
    "assert(speedup > 1)\n",
    "print(f\"(eval) eager median: {eager_med}, compile median: {compile_med}, speedup: {speedup}x\")\n",
    "print(\"~\" * 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
